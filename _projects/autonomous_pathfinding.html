---
layout: projects_layout
desc: ""
link_proj: true
title: "Autonomous Pathfinding in Simulated Environment"
desc: "Autonomous Pathfinding in a simulated game engine environment. Designed an algorithm which used in-game stereo camera input and Deep Learning based depth estimation technique for obstacle detection and navigation. <a class=\"tooltip\" href=\"https://dl.acm.org/citation.cfm?id=3175621\" target=\"_blank\">[Published at ICRAI, 2017]</a>"
pdate: "Aug, 2016 - Dec, 17"
project_pos: 1
---
<style type="text/css">

figcaption::before {
	content: "Figure " counter(figure) ". ";
}
</style>

<p class=""><em>Bachelor thesis project carried out during the final year of my studies at Delhi Technological University (with 3 other classmates). <a class="tooltip" href="https://dl.acm.org/citation.cfm?id=3175621" target="_blank">Published at ICRAI, 2017</a></em></p>

<h3>Motivation</h3>

<p>The state of the art techniques for environment sensing and autonomous navigation use <em>LIDAR</em> hardware with a <em>SLAM</em> (Simultaneous Localization And Mapping) algorithm. It is widely used in quad-copters and small vehicles.</p>
<p>During this project we explored the viability of a camera based approach for navigation, without relying on expensive hardware.</p>
<p>The motivation was two fold:
<ol>
<li>Humans <em>do not</em> have a specialized hardware like <em>LIDAR</em> for sensing our environment, we get by with our eyes. Logically the robots we design should do so too.</li>
<li>In comparison to cameras, <em>LIDAR</em> is expensive in terms of manufacturing as well as operation</li>
</ol>
</p>

<h3>Approach</h3>

<p>We had the basic idea to use a <em>CNN</em> (Convolutional Neural Network) to extract information from our scene and interface its output with a path planner. For a proof of concept scope, we decided to generate a scene depth map from the CNN, and use it for path planning.</p>

<p>Testing our approach with actual vehicles was not viable due to financial reasons. Real world datasets available were not large enough to train a deep neural network, and making one would have been too expensive</p>

<p>Due to these constraints we implemented our autonomous agent in a simulation (made using <a class="tooltip" target="_blank" href="https://www.panda3d.org/">Panda3D</a>). We used <a target="_blank" class="tooltip" href="https://shapenet.org/">Shapenet</a> (3D object database) to artificially generate a dataset for scene depth estimation.  </p>

<figure>
<img src="/assets/dataset.png">
<figcaption>Sample images from Dataset: Left Camera, Right Camera, and Scene Depth Ground Truth</figcaption>
</figure>

<p>We selected stereo image input instead of mono, so that more information about scene depth reaches the network. (See: <a class="tooltip" href="https://en.wikipedia.org/wiki/Stereopsis" target="_blank">Stereopsis</a>)</p>

<p>Armed with our cheaply generated dataset, we trained a <em>CNN</em> which produced a depth map of the scene in view given stereo input.</p>

<figure>
<img src="/assets/depthmap2.png">
<figcaption>Performance of the CNN on the depth estimation task</figcaption>

<p>For the last part we used the CNN on the in game camera footage for obstacle detection and avoidance. We evaluated our agent on different heuristics for pathfinding and baselined it with human performance on same task.</p>

<figure>
<div class="grid50">
<img src="/assets/environment.png">
<img src="/assets/godview.png">
</div>
<figcaption>Our environment simulation and agent in action</figcaption>
</figure>

<p>We were able to demonstrate that navigation without using specialized hardware could be possible with applications in small robots and vehicles. However, using heuristics in real world scenarios would not scale well. Thus, integrating the CNN with a SLAM algorithm would be the next step to test out this approach in actual vehicles.</p>

<p>Our paper regarding this project was accepted at <em>International Conference on Robotics and Artificial Intelligence</em> and published in December 2017.</p>